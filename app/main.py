import streamlit as st
import pandas as pd
try:
    # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆãŒsys.pathã«ã‚ã‚‹å ´åˆ
    from app import models, utils, assess  # çµ±åˆã•ã‚ŒãŸãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
except ModuleNotFoundError:
    # StreamlitãŒã‚¹ã‚¯ãƒªãƒ—ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆapp/ï¼‰ã‚’ã‚«ãƒ¬ãƒ³ãƒˆã«ã™ã‚‹å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    import os, sys
    sys.path.append(os.path.dirname(__file__))
    import models, utils, assess

# --- ãƒšãƒ¼ã‚¸è¨­å®š ---
st.set_page_config(page_title="åŠ´åƒç’°å¢ƒã‚¬ãƒãƒŠãƒ³ã‚¹ãƒã‚§ãƒƒã‚¯", page_icon="ğŸ›¡ï¸", layout="wide")

# --- åˆæœŸåŒ–å‡¦ç† ---
if 'openai_client' not in st.session_state:
    try:
        st.session_state.openai_client = models.get_openai_client()
        st.session_state.status_message = "<div style='text-align: right; color: green;'>âœ… OpenAIæ¥ç¶šå®Œäº†</div>"
    except (ValueError, ConnectionError) as e:
        st.session_state.openai_client = None
        st.session_state.status_message = f"<div style='text-align: right; color: red;'>âŒ {e}</div>"

# --- ã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆç”¨ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼ˆä½œæˆå‰ã«ä¸€åº¦ã ã‘è¨­å®šï¼‰ ---
if 'gpt5_reasoning_effort' not in st.session_state:
    st.session_state['gpt5_reasoning_effort'] = 'medium'
if 'gpt5_verbosity' not in st.session_state:
    st.session_state['gpt5_verbosity'] = 'medium'
if 'gpt4_temperature' not in st.session_state:
    st.session_state['gpt4_temperature'] = 0.0
if 'gpt4_max_tokens' not in st.session_state:
    st.session_state['gpt4_max_tokens'] = 4000

# --- ãƒ˜ãƒƒãƒ€ãƒ¼ ---
with st.container():
    st.title("åŠ´åƒç’°å¢ƒã‚¬ãƒãƒŠãƒ³ã‚¹ãƒã‚§ãƒƒã‚¯")
    if 'status_message' in st.session_state:
        st.markdown(st.session_state.status_message, unsafe_allow_html=True)
    # UIã®å„è¦ç´ ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã§ç®¡ç†
    col1, col2, col3 = st.columns([2, 3, 2])
    with col1:
        st.selectbox("ãƒ¢ãƒ‡ãƒ«", ("gpt-4.1-mini-2025-04-14", "gpt-4.1", "gpt-5-mini"), key="model_selection")
    with col2:
        st.multiselect("ãƒ«ãƒ¼ãƒ«ãƒ‘ãƒƒã‚¯", ["åŠ´å®‰", "å»ºç¯‰/é›»æ°—", "é£Ÿå“", "æƒ…å ±ä¿è­·", "ISO"], default=["åŠ´å®‰"], key="rule_pack_selection")
    with col3:
        if st.session_state.model_selection == "gpt-5-mini":
            reasoning = st.session_state.get("gpt5_reasoning_effort", "medium")
            verbosity = st.session_state.get("gpt5_verbosity", "medium")
            st.markdown(f"""<div style='font-size: 0.9em; color: grey; text-align: right;'>
                reasoning_effort={reasoning} | verbosity={verbosity}<br>
                æ¨è«–ã®æ·±ã•ã¨ã‚¢ã‚¦ãƒˆãƒ—ãƒƒãƒˆé‡ã‚’èª¿æ•´å¯èƒ½
            </div>""", unsafe_allow_html=True)
        else:
            temperature = st.session_state.get("gpt4_temperature", 0.0)
            max_tokens = st.session_state.get("gpt4_max_tokens", 4000)
            st.markdown(f"""<div style='font-size: 0.9em; color: grey; text-align: right;'>
                temperature={temperature} | max_tokens={max_tokens}<br>
                æ¸©åº¦è¨­å®šã¨ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’èª¿æ•´å¯èƒ½
            </div>""", unsafe_allow_html=True)

# ãƒ¢ãƒ‡ãƒ«åˆ¥ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®šUI
with st.expander("ğŸ”§ ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š", expanded=False):
    selected_model = st.session_state.model_selection
    
    if selected_model == "gpt-5-mini":
        st.markdown("**GPT-5 mini ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**")
        col1, col2 = st.columns(2)
        
        with col1:
            reasoning_effort = st.selectbox(
                "æ¨è«–ã®æ·±ã• (reasoning_effort)",
                ["minimal", "low", "medium", "high"],
                index=2,  # mediumã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
                help="minimal: é«˜é€Ÿãƒ»ä½ã‚³ã‚¹ãƒˆã€high: é«˜ç²¾åº¦ãƒ»é«˜ã‚³ã‚¹ãƒˆ",
                key="gpt5_reasoning_effort"
            )
            
            # æ¨è«–ã®æ·±ã•ã®èª¬æ˜
            if reasoning_effort == "minimal":
                st.info("âš¡ é«˜é€Ÿå‡¦ç†ãƒ»ä½ã‚³ã‚¹ãƒˆï¼ˆåŸºæœ¬çš„ãªåˆ†æï¼‰")
            elif reasoning_effort == "low":
                st.info("ğŸš€ é«˜é€Ÿå‡¦ç†ãƒ»ä¸­ã‚³ã‚¹ãƒˆï¼ˆæ¨™æº–çš„ãªåˆ†æï¼‰")
            elif reasoning_effort == "medium":
                st.info("âš–ï¸ ãƒãƒ©ãƒ³ã‚¹å‹ãƒ»ä¸­ã‚³ã‚¹ãƒˆï¼ˆæ¨å¥¨è¨­å®šï¼‰")
            else:  # high
                st.info("ğŸ¯ é«˜ç²¾åº¦ãƒ»é«˜ã‚³ã‚¹ãƒˆï¼ˆè¤‡é›‘ãªåˆ†æï¼‰")
        
        with col2:
            verbosity = st.selectbox(
                "ã‚¢ã‚¦ãƒˆãƒ—ãƒƒãƒˆé‡ (verbosity)",
                ["low", "medium", "high"],
                index=1,  # mediumã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
                help="low: ç°¡æ½”ã€high: è©³ç´°",
                key="gpt5_verbosity"
            )
            
            # ã‚¢ã‚¦ãƒˆãƒ—ãƒƒãƒˆé‡ã®èª¬æ˜
            if verbosity == "low":
                st.info("ğŸ“ ç°¡æ½”ãªè¦ç´„ï¼ˆè¦ç‚¹ã®ã¿ï¼‰")
            elif verbosity == "medium":
                st.info("ğŸ“‹ æ¨™æº–çš„ãªè©³ç´°ï¼ˆæ¨å¥¨è¨­å®šï¼‰")
            else:  # high
                st.info("ğŸ“š è©³ç´°ãªåˆ†æï¼ˆåŒ…æ‹¬çš„ï¼‰")
    
    elif selected_model in ["gpt-4.1-mini-2025-04-14", "gpt-4.1"]:
        st.markdown("**GPT-4.1ç³» ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**")
        col1, col2 = st.columns(2)
        
        with col1:
            temperature = st.slider(
                "æ¸©åº¦è¨­å®š (temperature)",
                min_value=0.0,
                max_value=2.0,
                value=0.0 if selected_model == "gpt-4.1-mini-2025-04-14" else 0.7,
                step=0.1,
                help="0.0: ç¢ºå®šçš„ãƒ»ä¸€è²«æ€§é‡è¦–ã€2.0: å‰µé€ çš„ãƒ»å¤šæ§˜æ€§é‡è¦–",
                key="gpt4_temperature"
            )
            
            # æ¸©åº¦è¨­å®šã®èª¬æ˜
            if temperature <= 0.3:
                st.info("ğŸ¯ ç¢ºå®šçš„ãƒ»ä¸€è²«æ€§é‡è¦–ï¼ˆç¾©å‹™åˆ¤å®šã«é©ã—ã¦ã„ã‚‹ï¼‰")
            elif temperature <= 0.7:
                st.info("âš–ï¸ ãƒãƒ©ãƒ³ã‚¹å‹ï¼ˆæ¨™æº–çš„ãªåˆ†æï¼‰")
            else:
                st.info("ğŸ’¡ å‰µé€ çš„ãƒ»å¤šæ§˜æ€§é‡è¦–ï¼ˆææ¡ˆç”Ÿæˆã«é©ã—ã¦ã„ã‚‹ï¼‰")
        
        with col2:
            max_tokens = st.slider(
                "æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•° (max_tokens)",
                min_value=1000,
                max_value=8000,
                value=4000,
                step=500,
                help="å¿œç­”ã®æœ€å¤§é•·ã‚’åˆ¶å¾¡",
                key="gpt4_max_tokens"
            )
            
            st.info(f"ğŸ“Š æœ€å¤§ {max_tokens} ãƒˆãƒ¼ã‚¯ãƒ³ã¾ã§ç”Ÿæˆ")
    
    # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ä¿å­˜ï¼ˆã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆã‚­ãƒ¼ã¯ã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆã«å§”ã­ã‚‹ãŸã‚ã€æ˜ç¤ºä»£å…¥ã—ãªã„ï¼‰
    
    # ç¾åœ¨ã®è¨­å®šã‚’è¡¨ç¤º
    st.markdown("---")
    st.markdown("**ç¾åœ¨ã®è¨­å®š**")
    if selected_model == "gpt-5-mini":
        st.code(f"ãƒ¢ãƒ‡ãƒ«: {selected_model}\næ¨è«–ã®æ·±ã•: {reasoning_effort}\nã‚¢ã‚¦ãƒˆãƒ—ãƒƒãƒˆé‡: {verbosity}")
    else:
        st.code(f"ãƒ¢ãƒ‡ãƒ«: {selected_model}\næ¸©åº¦: {temperature}\næœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°: {max_tokens}")

st.divider()

# --- ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ ---
left_column, right_column = st.columns(2)
with left_column:
    st.subheader("1. ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
    uploaded_files = st.file_uploader("ç›£æŸ»å¯¾è±¡ã®ç”»åƒã‚’ãƒ‰ãƒ©ãƒƒã‚°ï¼†ãƒ‰ãƒ­ãƒƒãƒ—", accept_multiple_files=True, type=['png', 'jpg', 'jpeg'])
    
    # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚ªãƒ—ã‚·ãƒ§ãƒ³
    col1, col2 = st.columns(2)
    with col1:
        remove_exif = st.checkbox("EXIFé™¤å»", value=True, help="ç”»åƒã‹ã‚‰ä½ç½®æƒ…å ±ãªã©ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’é™¤å»ã—ã¾ã™")
    with col2:
        blur_pii = st.checkbox("PIIã¼ã‹ã—", value=False, help="å€‹äººã‚’ç‰¹å®šã§ãã‚‹æƒ…å ±ã‚’ã¼ã‹ã—ã¾ã™ï¼ˆé–‹ç™ºä¸­ï¼‰")
    
    if uploaded_files:
        # ç”»åƒã®æ¤œè¨¼ã¨ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
        valid_files = []
        for file in uploaded_files:
            validation = utils.validate_image_file(file)
            if validation['valid']:
                valid_files.append(file)
            else:
                st.error(f"âŒ {file.name}: {validation['error']}")
        
        if valid_files:
            cols = st.columns(4)
            for i, file in enumerate(valid_files):
                with cols[i % 4]:
                    st.image(file, caption=file.name, use_container_width=True)
                    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿è¡¨ç¤º
                    metadata = utils.validate_image_file(file)['metadata']
                    st.caption(f"ğŸ“ {metadata['dimensions']} | ğŸ“¦ {metadata['size']/1024:.0f}KB")

with right_column:
    st.subheader("2. çŠ¶æ³èª¬æ˜")
    st.caption("ä¾‹: ã€é›»æ°—å·¥äº‹ã®é«˜æ‰€ä½œæ¥­ã§åˆ†é›»ç›¤äº¤æ›ã€‚ä½œæ¥­åºŠ2.5mã€è¦ªç¶±ã‚ã‚Šã€‚è©²å½“è¦æ ¼: åŠ´å®‰/é›»æ°—è¨­å‚™/ISMS(ç‰©ç†)ã€")
    st.text_area("ä½œæ¥­å†…å®¹ã¨è©²å½“/æº–æ‹ è¦æ ¼ã‚’ã§ãã‚‹ã ã‘å…·ä½“çš„ã«è¨˜è¼‰ã—ã¦ãã ã•ã„ã€‚", height=160, key="description_input")
    st.subheader("3. è§£æå®Ÿè¡Œ")
    if st.button("è§£æé–‹å§‹ â–¶", use_container_width=True, disabled=(st.session_state.openai_client is None)):
        if 'processed_data' in st.session_state: del st.session_state['processed_data']
        if not uploaded_files or not st.session_state.description_input.strip():
            st.warning("ç”»åƒã¨çŠ¶æ³èª¬æ˜ã®ä¸¡æ–¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        else:
            with st.spinner("AIãŒè§£æä¸­ã§ã™..."):
                # 1. ç”»åƒã®å®‰å…¨ãªå‡¦ç†
                image_results = []
                for file in uploaded_files:
                    result = utils.image_to_base64(file, remove_exif_data=remove_exif, blur_pii_data=blur_pii)
                    if result['success']:
                        image_results.append(result)
                    else:
                        st.error(f"âŒ {file.name}: {result['error']}")
                
                if not image_results:
                    st.error("æœ‰åŠ¹ãªç”»åƒãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
                    st.stop()
                
                base64_images = [result['base64'] for result in image_results]
                
                # 2. çµ±åˆåˆ†æï¼ˆã‚·ãƒ¼ãƒ³åˆ†é¡ + ãƒªã‚¹ã‚¯è©•ä¾¡ï¼‰
                with st.spinner("ä½œæ¥­ç¾å ´ã‚’åˆ†æã—ã€ãƒªã‚¹ã‚¯ã‚’è©•ä¾¡ä¸­..."):
                    # ãƒ¢ãƒ‡ãƒ«åˆ¥ã®ã‚«ã‚¹ã‚¿ãƒ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æº–å‚™
                    custom_params = None
                    if st.session_state.model_selection == "gpt-5-mini":
                        custom_params = {
                            "reasoning_effort": st.session_state.get("gpt5_reasoning_effort", "medium"),
                            "verbosity": st.session_state.get("gpt5_verbosity", "medium")
                        }
                    elif st.session_state.model_selection in ["gpt-4.1-mini-2025-04-14", "gpt-4.1"]:
                        custom_params = {
                            "temperature": st.session_state.get("gpt4_temperature", 0.0),
                            "max_tokens": st.session_state.get("gpt4_max_tokens", 4000)
                        }
                    
                    ai_response_json = models.call_vision_api(
                        st.session_state.openai_client, 
                        st.session_state.description_input, 
                        base64_images, 
                        st.session_state.model_selection,
                        custom_params
                    )
                    processed_data = assess.process_ai_response(ai_response_json)
                
                st.session_state.processed_data = processed_data
                if "error" in processed_data:
                    error_msg = processed_data['error']
                    st.error(f"è§£æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {error_msg}")
                    
                    # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿é–¢é€£ã®ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯è©³ç´°ã‚’è¡¨ç¤º
                    if "ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿" in error_msg or "APIãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼" in error_msg:
                        st.warning("ğŸ’¡ **è§£æ±ºæ–¹æ³•**: ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®šã‚’ç¢ºèªã—ã€é©åˆ‡ãªå€¤ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
                        st.info("**æ¨å¥¨è¨­å®š**: GPT-5 miniã®å ´åˆã¯reasoning_effort=medium, verbosity=mediumã‚’è©¦ã—ã¦ãã ã•ã„ã€‚")
                else:
                    # ã‚·ãƒ¼ãƒ³åˆ†æçµæœã®è¡¨ç¤º
                    if 'scene_tags' in processed_data and processed_data['scene_tags']:
                        st.success(f"ğŸ” **æ¤œå‡ºã•ã‚ŒãŸä½œæ¥­ç¾å ´**: {', '.join(processed_data['scene_tags'])}")
                    if 'confidence' in processed_data:
                        st.info(f"ğŸ“Š **åˆ†æä¿¡é ¼åº¦**: {processed_data['confidence']:.1%}")
                    st.success("AIã«ã‚ˆã‚‹çµ±åˆè§£æãŒå®Œäº†ã—ã¾ã—ãŸã€‚çµæœã‚’ä»¥ä¸‹ã«è¡¨ç¤ºã—ã¾ã™ã€‚")
                    st.caption("â€» æœ¬çµæœã¯ç›£æŸ»æ”¯æ´ã‚’ç›®çš„ã¨ã—ãŸè‡ªå‹•è§£æã§ã™ã€‚æ³•æ”¹æ­£ç­‰ã«ã‚ˆã‚Šæœ€æ–°ã§ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚æœ€çµ‚ç¢ºèªã¯åˆ©ç”¨è€…ã®è²¬ä»»ã§ãŠé¡˜ã„ã—ã¾ã™ã€‚")

st.divider()

# --- çµæœè¡¨ç¤ºã‚¿ãƒ– ---
st.subheader("4. è§£æçµæœ")
tab1, tab2, tab3, tab4, tab5 = st.tabs(["â‘  ç¾©å‹™(æ¸©åº¦0)", "â‘¡ ææ¡ˆ(æ¸©åº¦0.7)", "â‘¢ é‡è¦åº¦ãƒ“ãƒ¥ãƒ¼", "â‘£ Q&Aãƒ­ã‚°", "â‘¤ PDF"])

if 'processed_data' in st.session_state and "error" not in st.session_state.processed_data:
    data = st.session_state.processed_data
    
    # ã‚·ãƒ¼ãƒ³æ¨å®šçµæœã®è¡¨ç¤º
    if 'scene_tags' in data and data['scene_tags']:
        st.info(f"ğŸ” **æ¤œå‡ºã•ã‚ŒãŸä½œæ¥­ç¾å ´**: {', '.join(data['scene_tags'])}")
    
    if 'applied_rules' in data and data['applied_rules']:
        st.info(f"ğŸ“‹ **é©ç”¨ã•ã‚ŒãŸãƒ«ãƒ¼ãƒ«**: {', '.join(data['applied_rules'])}")
    
    # --- ç¾©å‹™ã‚¿ãƒ– --- 
    with tab1:
        st.header("ç¾©å‹™ï¼ˆå¿…é ˆ/æº–æ‹ å¿…é ˆï¼‰äº‹é …ã®æŒ‡æ‘˜")
        findings = data.get("findings", [])
        if not findings:
            st.success("ç¾©å‹™é•åã«è©²å½“ã™ã‚‹æŒ‡æ‘˜äº‹é …ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        for item in findings:
            with st.container(border=True):
                col1, col2 = st.columns([4, 1])
                with col1:
                    st.markdown(f"**{item.get('domain', 'N/A')} / {item.get('rule_id', 'N/A')}**")
                with col2:
                     st.error(f"Risk Score: {item.get('risk_score', 0)}")
                st.markdown(f"**åˆ¤å®š:** {item.get('judgment', 'N/A')}")
                st.markdown(f"**è¦³å¯Ÿæ ¹æ‹ :** {item.get('observation_reason', 'N/A')}")
                st.markdown(f"**è¦æ ¼æ ¹æ‹ :** {item.get('standard_reason', 'N/A')}")
                if item.get('additional_question'):
                    st.info(f"**è¿½åŠ è³ªå•:** {item.get('additional_question', 'N/A')}")

    # --- ææ¡ˆã‚¿ãƒ– --- 
    with tab2:
        st.header("ææ¡ˆï¼ˆãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ï¼‰äº‹é …")
        suggestions = data.get("suggestions", [])
        if not suggestions:
            st.info("ææ¡ˆäº‹é …ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        for item in suggestions:
            with st.container(border=True):
                st.markdown(f"**{item.get('domain', 'N/A')}**")
                st.markdown(f"**ææ¡ˆ:** {item.get('suggestion', 'N/A')}")
                st.markdown(f"**æ ¹æ‹ :** {item.get('evidence', 'N/A')}")

    # --- é‡è¦åº¦ãƒ“ãƒ¥ãƒ¼ã‚¿ãƒ– --- 
    with tab3:
        st.header("ãƒªã‚¹ã‚¯é‡è¦åº¦ãƒ“ãƒ¥ãƒ¼")
        if not findings:
            st.info("ã‚°ãƒ©ãƒ•åŒ–ã™ã‚‹æŒ‡æ‘˜äº‹é …ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        else:
            chart_data = pd.DataFrame(
                [{"æŒ‡æ‘˜äº‹é …": f"{f.get('rule_id')}", "ãƒªã‚¹ã‚¯ã‚¹ã‚³ã‚¢": f.get('risk_score')} for f in findings]
            ).set_index("æŒ‡æ‘˜äº‹é …")
            st.bar_chart(chart_data)

    with tab4:
        st.header("AIã¨ã®Q&Aãƒ­ã‚°ï¼ˆä¸è¶³æƒ…å ±ã®ç¢ºèªï¼‰")
        questions = [f for f in data.get("findings", []) if f.get("additional_question")]
        if not questions:
            st.info("ç¾åœ¨ã€ç¢ºèªã™ã¹ãè¿½åŠ è³ªå•ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
        else:
            for q in questions:
                st.write(f"- {q.get('additional_question')}")

    with tab5:
        st.header("PDFãƒ¬ãƒãƒ¼ãƒˆã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ")
        st.info("ã“ã®æ©Ÿèƒ½ã¯ç¾åœ¨é–‹ç™ºä¸­ã§ã™ã€‚")
else:
    with tab1:
        st.info("è§£æã‚’é–‹å§‹ã™ã‚‹ã¨ã€ã“ã“ã«ç¾©å‹™ã«é–¢ã™ã‚‹æŒ‡æ‘˜ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")
    with tab2:
        st.info("è§£æã‚’é–‹å§‹ã™ã‚‹ã¨ã€ã“ã“ã«ææ¡ˆäº‹é …ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")
    with tab3:
        st.info("è§£æã‚’é–‹å§‹ã™ã‚‹ã¨ã€ã“ã“ã«ãƒªã‚¹ã‚¯ã®ã‚°ãƒ©ãƒ•ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")